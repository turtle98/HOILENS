"""
hoi_sft_dataset.py — dataset wrapper for HOI SFT fine-tuning.

Subclasses DataFactory to add a 'text_label' field to each target dict.

Two modes:
  1. Pre-extracted captions (preferred):
       Pass caption_file=/path/to/hico_train_captions.json
       The file maps filename → detailed caption string generated by the base
       Qwen model (see scripts/extract_hoi_captions.py).
       Format per entry (example):
         "[1] person riding a bicycle: The person sits upright on the seat...\n
          [2] person holding a bottle: The person grips a clear bottle..."

  2. Fallback structured format:
       When no caption_file is provided (or a filename is missing from the
       cache), build_target_text_detailed() produces:
         "[1] person riding a bicycle\n[2] person holding a bottle"
       which is still more explicit than the original comma-separated format.
"""

import json
import os
import torch
from datasets import DataFactory
from methods.hoi_prompt_utils import build_target_text_detailed


class HOISFTDataset(DataFactory):
    """
    Identical to DataFactory but __getitem__ also stores a 'text_label' string
    in the target dict for the SFT cross-entropy loss.

    Args:
        caption_file (str | None): Path to a JSON file produced by
            scripts/extract_hoi_captions.py.  Maps image filename →
            detailed caption string.  If None or a filename is missing,
            falls back to the structured build_target_text_detailed() output.
        All other args are forwarded to DataFactory.__init__.
    """

    def __init__(self, *args, caption_file: str | None = None, **kwargs):
        super().__init__(*args, **kwargs)

        self._captions: dict[str, str] = {}
        if caption_file is not None:
            if not os.path.exists(caption_file):
                raise FileNotFoundError(
                    f"caption_file not found: {caption_file!r}\n"
                    "Run scripts/extract_hoi_captions.py first."
                )
            with open(caption_file, "r") as f:
                self._captions = json.load(f)
            print(
                f"[HOISFTDataset] Loaded {len(self._captions)} pre-extracted "
                f"captions from {caption_file}"
            )
        else:
            print(
                "[HOISFTDataset] No caption_file provided — using "
                "build_target_text_detailed() fallback."
            )

    def __getitem__(self, i):
        (image, image_clip), target = super().__getitem__(i)

        filename = target.get("filename", "")

        # Try pre-extracted caption first
        if filename in self._captions:
            caption = self._captions[filename].strip()
            # Guard against empty strings saved during failed extractions
            if not caption:
                caption = self._fallback_caption(target)
        else:
            caption = self._fallback_caption(target)

        target["text_label"] = caption
        return (image, image_clip), target

    # ------------------------------------------------------------------

    def _fallback_caption(self, target: dict) -> str:
        if "hoi" in target:
            hoi_indices = target["hoi"]
        else:
            hoi_indices = target.get("labels", torch.zeros(0, dtype=torch.long))
        return build_target_text_detailed(hoi_indices)


# ---------------------------------------------------------------------------
# Collate
# ---------------------------------------------------------------------------

def hoi_sft_collate(batch):
    """
    Collate function for HOISFTDataset.

    text_label strings stay as Python strings inside the target dicts —
    no special handling needed since they are used per-sample in the model
    forward pass.
    """
    images  = []
    targets = []
    for (im, im_clip), tar in batch:
        images.append((im, im_clip))
        targets.append(tar)
    return images, targets
